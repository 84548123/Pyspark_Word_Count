{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p8_gD6fcufO"
      },
      "source": [
        "# Program 1: Word Count\n",
        "\n",
        "## This program will demonstrate creating an RDD from a text dataset, performing transformations to count the occurences of each word and actions to collect and print the results.\n",
        "\n",
        "#Aryan Shetty\n",
        "#23MBD029"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0D3AtjK7csJD",
        "outputId": "4688f659-84c8-4bc1-964c-9b67feecea92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=d18b2a23f2a25c256d5ae4cfd5a7a1eb16d55f3aaba1f9ae7d8f69357a8cea9b\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uaR_coPlczt-"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkConf,SparkContext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zEc6xm3Gc_K0"
      },
      "outputs": [],
      "source": [
        "#Initializing Spark Context\n",
        "conf=SparkConf().setAppName('PySparkWordCountPrac').setMaster('local')\n",
        "sc=SparkContext(conf=conf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mM8ra_U-dId_",
        "outputId": "53cfc1f3-017e-4040-edf5-e9abad82cad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', 'World', 'Hello', 'Spark', 'Hello', 'RDD', 'Hello', 'Aryan', '', 'Hello', 'PySpark']\n"
          ]
        }
      ],
      "source": [
        "#Creating an RDD from a list of words\n",
        "data=['Hello World', 'Hello Spark','Hello RDD','Hello Aryan ','Hello PySpark']\n",
        "rdd=sc.parallelize(data)\n",
        "word_rdd_=rdd.flatMap(lambda x:x.split(' '))  #creating a new flatmap rdd of splitted sentences from the previous rdd (transformation)\n",
        "print(word_rdd_.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0LLCF3ZSd-8U",
        "outputId": "471904b6-e295-42ea-e4fc-a31807e7f5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hello', 1), ('World', 1), ('Hello', 1), ('Spark', 1), ('Hello', 1), ('RDD', 1), ('Hello', 1), ('Aryan', 1), ('', 1), ('Hello', 1), ('PySpark', 1)]\n"
          ]
        }
      ],
      "source": [
        "word_pairs_rdd_=word_rdd_.map(lambda x:(x,1)) #creating another rdd using map function to map all words with count 1\n",
        "print(word_pairs_rdd_.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "SV17epRnePP0",
        "outputId": "ab85fb37-d116-4105-9ca5-ee6bb55c1852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Hello', 5), ('World', 1), ('Spark', 1), ('RDD', 1), ('Aryan', 1), ('', 1), ('PySpark', 1)]\n"
          ]
        }
      ],
      "source": [
        "word_counts_rdd_=word_pairs_rdd_.reduceByKey(lambda x,y:x+y) #creating another rdd using reducebykey function that will add same words count\n",
        "print(word_counts_rdd_.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RKiVi82HeY9E"
      },
      "outputs": [],
      "source": [
        "word_counts_=word_counts_rdd_.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CYjDGMIhekJM",
        "outputId": "9174e041-9b6f-4799-d096-7b8cebf6f5a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello:5\n",
            "World:1\n",
            "Spark:1\n",
            "RDD:1\n",
            "Aryan:1\n",
            ":1\n",
            "PySpark:1\n"
          ]
        }
      ],
      "source": [
        "for word, count in word_counts_:\n",
        "    print(f'{word}:{count}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vzzfGkc7eqB1"
      },
      "outputs": [],
      "source": [
        "sc.stop()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}